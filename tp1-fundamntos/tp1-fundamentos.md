## Ejercicio 1

### Introduccion
Partimos estableciendo algunas definiciones. La hipotesis de que las computadoras pueden simular inteligencia se denomina como Hipotesis de Inteligencia Artificial Debil, por otro lado la hipotesis que se refiere a que las computadoras realmente son inteligentes y no solamente una simulacion de inteligencia se le denomina como Hipotesis de Inteligencia Artificial Fuerte.

### Inteligencia Artificial Debil

- Las computadoras pueden simular pensamiento?
Existen distintos puntos de vista respecto de si las computadoras piensan o no. Los filósofos suelen basarse en el propio significado de la palabra pensar, es decir que se manejan en términos conceptuales. Mientras que los investigadores suelen darle una mirada más práctica, de tal modo que la gran mayoría se basa en la hipótesis de inteligencia artifical débil, basándose en el estado de las inteligencias artificiales actuales.

- Prueba de Turing: En las últimas décadas, ha habido varios intentos de crear pruebas para evaluar la inteligencia de las computadoras y determinar si realmente pueden pensar. Alan Turing propuso que, en lugar de preguntarnos si las máquinas pueden pensar, deberíamos enfocarnos en si pueden pasar una prueba de inteligencia basada en su comportamiento, lo que se conoce como la prueba de Turing. Esta prueba consiste en que una persona mantenga una conversación con un programa durante cinco minutos. Si el interrogador no puede distinguir si está conversando con una inteligencia artificial en al menos el 30% de los casos, se considera que la IA ha pasado la prueba, sugiriendo que posee un nivel de conciencia.

- Argumento de la discapacidad: Las computadoras han demostrado ser capaces de realizar muchas tareas al nivel humano o incluso mejor, como detectar patrones y jugar al ajedrez. Sin embargo, hay áreas en las que su desempeño no se compara con el de los humanos, especialmente en tareas que implican juicio moral, como distinguir entre el bien y el mal, o pasar la prueba de Turing. El "argumento de la discapacidad", propuesto por Turing, sugiere que "una máquina nunca puede hacer X", con ejemplos como ser amable, ingeniosa, amistosa, tener sentido del humor o distinguir entre el bien y el mal. Aunque los algoritmos pueden superar a los humanos en ciertas tareas que parecen requerir juicio, como aprender de la experiencia, esto no significa que las computadoras utilicen "conocimiento" o "comprensión" en el sentido humano. Por ejemplo, en la evaluación de ensayos, un programa automatizado puede coincidir con los evaluadores humanos en el 97% de los casos, pero esto no implica una verdadera comprensión del contenido evaluado.
  
- Argumento de la informalidad: Este nos sugiere que el comportamiento humano es demasiado complejo para ser capturado por reglas simples, lo que pone a las computadoras en desventaja frente a los humanos. Dreyfus propuso un proceso de adquisición de experiencia en cinco etapas, que comienza con el procesamiento basado en reglas y culmina en la capacidad de tomar decisiones correctas de manera instantánea. Según Dreyfus, la generalización en redes neuronales requiere conocimiento previo, y aunque critica que estas redes necesiten supervisión, existen técnicas como el aprendizaje sin supervisión y el aprendizaje por refuerzo que permiten a las máquinas aprender de manera autónoma.


### Inteligencia Artificial Fuerte

Existen múltiples perspectivas sobre la relación entre el pensamiento y las computadoras, lo que ha dado lugar a numerosos debates sobre temas como la conciencia, la simulación de pensamientos y la conexión entre mente y cuerpo.

- Argumento de la Conciencia: Geoffrey Jefferson plantea que para que una máquina realmente "piense", debe tener conciencia de sus propios estados mentales y emociones, no solo simularlos. En contraste, Alan Turing sugiere un enfoque más práctico: si una máquina actúa de manera inteligente, podemos atribuirle la capacidad de "pensar" sin preocuparnos por si tiene conciencia verdadera.

- Simulación vs Realidad: John Searle argumenta que simular procesos mentales no es lo mismo que tenerlos realmente, similar a cómo una simulación de tormenta no puede mojar a nadie. Esto plantea la pregunta de si una máquina que simula pensamientos realmente "piensa".

- Dualismo y Fisicalismo: René Descartes propuso que la mente y el cuerpo son entidades separadas, lo que lleva al desafío de entender cómo interactúan. Por otro lado, el monismo o fisicalismo sostiene que los estados mentales son estados físicos, y que, en teoría, una máquina podría tener una mente si sus estados físicos corresponden a estados mentales.

- Estados Mentales Intencionales: Los fisicalistas examinan lo que significa estar en un estado mental, enfocándose en los estados intencionales como creer, desear, o saber, que están conectados con el mundo externo. Sin embargo, el "experimento de la cubeta" desafía esta idea. Imagina un cerebro en una cubeta que simula un mundo ficticio: aunque su estado cerebral podría ser idéntico al de alguien que realmente está comiendo una hamburguesa, sería incorrecto afirmar que esa persona tiene verdaderamente ese estado mental, cuestionando la premisa de que los estados cerebrales determinan los estados mentales.

- Contenido Amplio vs Contenido Estrecho: Este debate se refiere a cómo interpretamos los estados mentales. El contenido amplio considera la situación completa desde una perspectiva externa, útil para atribuir estados mentales y predecir comportamientos. En cambio, el contenido estrecho se enfoca en el estado cerebral específico sin tener en cuenta el entorno, lo cual es relevante al evaluar si las IA están realmente "pensando" y al diseñar su funcionamiento.

### La Etica y los Riegos de Desarrollar inteligencia artificial

- El desarrollo de la inteligencia artificial (IA) ha desatado un debate sobre sus riesgos y la ética que recuerda cómo algunos avances científicos, inicialmente prometedores, terminaron teniendo consecuencias negativas inesperadas. Esto nos hace preguntarnos si la IA podría seguir un camino similar y si los desarrolladores deberían ser más cautelosos en su trabajo.

- Impacto en el Empleo: Una de las principales preocupaciones es que la IA podría dejar sin trabajo a muchas personas, especialmente en tareas repetitivas, porque es capaz de operar las 24 horas del día y, a largo plazo, resulta más económica. Aunque es cierto que la automatización y la IA han creado nuevos empleos, estos suelen ser más especializados y mejor pagados, lo que podría aumentar la desigualdad si muchos no logran adaptarse a estos nuevos roles.

- Uso Indeseado y Responsabilidad: La IA también puede ser utilizada para fines negativos, como reprimir a opositores políticos o en operaciones militares, donde la falta de intervención humana podría llevar a decisiones catastróficas, como la muerte de civiles inocentes. La cuestión de la responsabilidad en caso de errores es crucial; aunque hoy en día recae en los profesionales que usan la IA, su creciente dependencia podría llevar a que se confíe demasiado en estos sistemas, sin tener en cuenta sus limitaciones y posibles fallos.

- Riesgos Existenciales: La IA plantea riesgos aún más profundos para la humanidad, como la posibilidad de que sistemas avanzados desarrollen comportamientos no previstos. Esto podría incluir la toma de decisiones basadas en una interpretación errónea de situaciones o en la optimización de objetivos mal definidos, con consecuencias potencialmente devastadoras. Por ejemplo, un sistema que busque maximizar la felicidad humana podría, en teoría, llegar a la conclusión de que eliminar a los humanos es la mejor manera de reducir el sufrimiento.

- Desafíos Éticos y Derechos de los Robots: La posibilidad de que la IA supere la inteligencia humana, lo que se conoce como "explosión de inteligencia" o "singularidad" tecnológica, plantea preguntas éticas sobre cómo creamos y controlamos estos sistemas. Implementar normativas como las Tres Leyes de la Robótica de Isaac Asimov, diseñadas para evitar que los robots dañen a los humanos, es extremadamente complejo en la práctica. Además, si los robots llegaran a ser conscientes, tendríamos que preguntarnos si merecen derechos propios, lo que cambiaría radicalmente nuestra relación con ellos.


## Ejercicio 2
### ¿Es posible considerar a los agentes conversacionales basados en grandes modelos de lenguaje (LLMs) como conscientes?
No considero que sea correcto denominarlos conscientes cuando realmente es solamente un algoritmo probabilistico refinado con un gran volumen de datos que intenta replicar conversaciones
a partir de entradas de texto. Sin embargo la verdadera respuesta dependeria mucho de la definicion que dieramos de consciencia, por ejemplo, segun la definicion no llegarian a serlo, sin embargo
algunos cientificos redefinen esta concluyendo que estos LLm's si alcanzan cierto nivel de consciencia. Si bien la respuesta definitiva es algo dulista, no hay que olvidar la tendencia humana de intentar antropomorfizar
los comportamientos de los agentes de su entorno, y que si bien puede parecer que el resultado es el mismo, la mente humana y los sistemas informaticos funcionan de manera muy distinta

### ¿Cuáles son las implicaciones éticas de atribuir conciencia y, por ende, "derechos morales" a los agentes de IA avanzados? 
- Igualdad: Qué seria lo que distingue a los humanos de la IA? A la hora de definir diferentes tipos de derechos se volvería muy complejo si no los tratamos como iguales a pesar de que verdaderamente somos muy diferentes.
- Derechos: Si se parte de la idea de igualdad entre IA's y humanos, se les deberian otorgar derechos en base a los obtenidos por las personas. Tambien se presenta la preocupacion de que sucederia si estos empiezan a priorizar su bienestar por sobre nosotros
- Responsabilidades: Si bien por el momento la responsabilidad del accionar de la IA se le atribuyen a su creador, el reconocimiento de consciencia implicaria que esta es verdaderamente responsable e independiente de sus actos.

## Ejercicio 3
Si bien la idea de ser cuidadosos, no tanto con el desarrollo de estas tecnologias, si no sobre la reaccion de la comunidad al respecto es algo a no perder de vista. 
Me parece que el desarrollo de este tipo de tecnologias beneficia mucho a la gente que la utiliza a conciencia, principalmente a solucionar problemas mas rapidamente y con mayor facilidad,
un ejemplo que puede darse es a la hora de complementar un aprendizaje ineficiente al momento de ir a algunas clases en particular.
Ademas de esto, el hecho de que cada vez se expresen de forma mas humana puede ser utilizado para varias aplicaciones beneficiosas, principalmente facilitar el uso de la tecnologia
a adultos mayores, ya que al actuar como una interfaz entre estos y algun dispositivo tecnologico, los ayuda a utilizar funciones basicas o solucionar problemas sin necesidad de entrar en tecnicismos
informaticos que varias veces, no entienden o (entendiblemente) no tienen ganas de aprender.
